{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59cbda1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pajag\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\pajag\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.4sp5sua7cbgxueoc35yp2asoicyyeqzz.gfortran-win_amd64.dll\n",
      "C:\\Users\\pajag\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72f6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a786ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path):\n",
    "    \n",
    "    image_filenames = os.listdir(folder_path)\n",
    "    images = []\n",
    "    i = 0\n",
    "    for image_filename in image_filenames:\n",
    "        image = cv2.imread(os.path.join(folder_path, image_filename))\n",
    "        images.append(image)\n",
    "        i = i+1\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca0bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = load_images_from_folder('C://Users//pajag//OneDrive//Desktop//frame//test_real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2666025",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_test = load_images_from_folder('C://Users//pajag//OneDrive//Desktop//frame//test_fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dfd63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = load_images_from_folder('C://Users//pajag//OneDrive//Desktop//frame//real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c439f7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = load_images_from_folder('C://Users//pajag//OneDrive//Desktop//frame//fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cbc94e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1504, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde058d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "809ed68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1504, 224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16b9eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(array):\n",
    "    resized = []\n",
    "    for img in array:\n",
    "        img = img / 255.0\n",
    "        resized.append(img)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39ac90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = preprocess_images(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "480da623",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images = preprocess_images(fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b559f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_pre = preprocess_images(real_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d5e175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_test_pre = preprocess_images(fake_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a540148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7301f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.DataFrame({'image':real_images, 'label': '0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1908a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = pd.DataFrame({'image':fake_images, 'label': '1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "846f92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_df = pd.DataFrame({'image':real_test_pre, 'label': '0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "583176c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_test_df = pd.DataFrame({'image':fake_test_pre, 'label': '1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d32c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([real_df,fake_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cef106dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2784"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c66da804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[np.random.permutation(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04893f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([real_test_df,fake_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1294bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a28778a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = df.iloc[np.random.permutation(len(df_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28428aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = df['image']\n",
    "y_batch = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3694c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = [tf.convert_to_tensor(img) for img in x_batch]\n",
    "x_batch = tf.stack(x_batch)\n",
    "y_batch = tf.convert_to_tensor(y_batch)\n",
    "y_batch = tf.strings.to_number(y_batch, out_type=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba72d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch_test = df_test['image']\n",
    "y_batch_test = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a00fb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch_test = [tf.convert_to_tensor(img) for img in x_batch_test]\n",
    "x_batch_test = tf.stack(x_batch_test)\n",
    "y_batch_test = tf.convert_to_tensor(y_batch_test)\n",
    "y_batch_test = tf.strings.to_number(y_batch_test, out_type=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "127aafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "073c702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "caca45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c86c041b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "446/446 [==============================] - 199s 438ms/step - loss: 0.6213 - accuracy: 0.6444 - val_loss: 0.5361 - val_accuracy: 0.7307\n",
      "Epoch 2/5\n",
      "446/446 [==============================] - 197s 443ms/step - loss: 0.4895 - accuracy: 0.7652 - val_loss: 0.4632 - val_accuracy: 0.7648\n",
      "Epoch 3/5\n",
      "446/446 [==============================] - 191s 428ms/step - loss: 0.4569 - accuracy: 0.7813 - val_loss: 0.4222 - val_accuracy: 0.7953\n",
      "Epoch 4/5\n",
      "446/446 [==============================] - 193s 432ms/step - loss: 0.3855 - accuracy: 0.8092 - val_loss: 0.3579 - val_accuracy: 0.8115\n",
      "Epoch 5/5\n",
      "446/446 [==============================] - 163s 366ms/step - loss: 0.3407 - accuracy: 0.8433 - val_loss: 0.3895 - val_accuracy: 0.8205\n"
     ]
    }
   ],
   "source": [
    "model = model.fit(x_batch,y_batch,batch_size=5,epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7868bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86a1ca2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6212847828865051,\n",
       " 0.4894959330558777,\n",
       " 0.4569321274757385,\n",
       " 0.385530561208725,\n",
       " 0.3407454788684845]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a557b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename):\n",
    "    model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e017097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data):\n",
    "    test_images = [tf.convert_to_tensor(image) for image in data['image'].values]\n",
    "    test_images = tf.stack(test_images)\n",
    "\n",
    "    test_labels = tf.convert_to_tensor(data['label'].values)\n",
    "    test_labels = tf.strings.to_number(test_labels, out_type=tf.float32)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2969fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accurcy = evaluate_model(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c6a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, \"deepfake_detection_vid_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
